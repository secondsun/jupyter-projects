{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Breakdown\n",
    "\n",
    "Up to this point I've taken this project from a simple dataset all the way to a high-performing predictive model. Now, I'll show you how I can use this model to predict brand new (**raw**) data and package the work together into an executable script. Here, in part 4 of 4, we'll import libraries and load our model from Part 3.\n",
    "\n",
    "Then, we'll cover these steps:\n",
    "\n",
    "1. [Confirm your model was saved correctly](#confirm)\n",
    "2. [Write pre-modeling functions](#pre-model)\n",
    "3. [Construct a model class](#model-class)\n",
    "4. [Method 1: Jupyter notebook](#jupyter)\n",
    "5. [Method 2: Executable script](#exectuable)\n",
    "\n",
    "<br><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, let's import libraries and load the model.\n",
    "\n",
    "First, let's import the libraries that we'll need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pickle for reading model files\n",
    "import pickle\n",
    "\n",
    "# Scikit-Learn for Modeling\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, load the final model saved from Part 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load final_model.pkl as model\n",
    "with open('final_model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, let's begin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span id=\"confirm\"></span>\n",
    "### 1. Confirm the model was saved correctly\n",
    "\n",
    "A nice and quick sanity check I can do is confirm that the model was saved correctly.\n",
    "<br>\n",
    "**First, I'm going display the model object. This helps to confirm a few key details:**\n",
    "* It should be a model <code style=\"color:steelblue\">Pipeline</code>.\n",
    "* The first step should be a <code style=\"color:steelblue\">StandardScaler</code> preprocessing step.\n",
    "* The second step should be a <code style=\"color:steelblue\">RandomForestClassifier</code> model.\n",
    "\n",
    "Then I will load my analytical_base_table, split it into training and test sets, and use it to predict <code style=\"color:steelblue\">X_test</code> again just like I did in Part 3. However, the difference now is that I'm using the <code style=\"color:steelblue\">roc_auc_score</code> instead of the <code style=\"color:steelblue\">roc_curve</code> and <code style=\"color:steelblue\">auc</code> of said curve. This allows me to skip calculating the <code style=\"color:steelblue\">roc_curve</code> as an intermediate step and go right to the <code style=\"color:steelblue\">auc</code> which is the metric I'm after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestclassifier', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=0.33, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_i...imators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=123, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display model object\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load analytical base table used in Module 4\n",
    "abt_df = pd.read_csv('analytical_base_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate object for target variable\n",
    "y = abt_df['status']\n",
    "\n",
    "# Create separate object for input features\n",
    "X = abt_df.drop('status', axis=1)\n",
    "\n",
    "# Split X and y into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 0.9915201892159932\n"
     ]
    }
   ],
   "source": [
    "# Predict X_test\n",
    "pred = model.predict_proba(X_test)\n",
    "\n",
    "# Get just the prediction for the postive class (1)\n",
    "pred = [p[1] for p in pred]\n",
    "\n",
    "# Print AUROC\n",
    "print('AUROC:', roc_auc_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'm going to load some brand new, **raw data** that we've never seen before. Then we'll see what happens when we try to apply the model to this raw dataset. As one might predict, this throws an error because our model is based on the <code style=\"color:steelblue\">analytical_base_table</code> with all the data cleaning and feature engineering we did in Part 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'project_files/unseen_raw_data.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5fff2d7db7f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mraw_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'project_files/unseen_raw_data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'project_files/unseen_raw_data.csv' does not exist"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_csv('project_files/unseen_raw_data.csv')\n",
    "\n",
    "print( raw_data.shape )\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should throw an error\n",
    "pred = model.predict_proba(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center; margin: 40px 0 40px 0; font-weight:bold\">\n",
    "<a href=\"#toc\">Back to Contents</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span id=\"pre-model\"></span>\n",
    "### 2. Write pre-modeling functions\n",
    "\n",
    "All we need to do is write a few functions to **convert the raw data to the same format as the analytical base table**. So I'll now write a function called <code style=\"color:steelblue\">clean_data()</code> that bundles together all of the data cleaning steps. Once I do that I create a new DataFrame named <code style=\"color:steelblue\">cleaned_data</code> using this new function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    # Drop duplicates\n",
    "    df.drop_duplicates()\n",
    "    # Drop temporary workers\n",
    "    df = df[df.department != 'temp']\n",
    "    # Missing filed_complaint values should be 0\n",
    "    df['filed_complaint'] = df['filed_complaint'].fillna(0)\n",
    "    # Missing recently_promoted values should be 0\n",
    "    df['recently_promoted'] = df['recently_promoted'].fillna(0)\n",
    "    # 'information_technology' should be 'IT'\n",
    "    df.department.replace('information_technology', 'IT', inplace=True)\n",
    "    # Fill missing values in department with 'Missing'\n",
    "    df['department'].fillna('Missing', inplace=True)\n",
    "    # Indicator variable for missing last_evaluation\n",
    "    df['last_evaluation_missing'] = df['last_evaluation'].isnull().astype(int)\n",
    "    # Fill missing values in last_evaluation with 0\n",
    "    df['last_evaluation'].fillna(0, inplace=True)\n",
    "    # Return cleaned dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a new DataFrame named <code style=\"color:steelblue\">cleaned_data</code> using the function you just wrote.**\n",
    "* Then display its first 5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cleaned_new_data \n",
    "cleaned_data = clean_data(raw_data)\n",
    "\n",
    "# Display first 5 rows\n",
    "cleaned_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I write a function called <code style=\"color:steelblue\">engineer_features()</code> that compiles all of the feature engineering steps making sure not to include any steps used to process the target variable since I don't have that variable when predicting new, unseen observations. Then I create a new DataFrame named <code style=\"color:steelblue\">augmented_data</code> using the newly written function, remembering to pass in <code style=\"color:steelblue\">cleaned_data</code> and not <code style=\"color:steelblue\">raw_data</code>. To double check the accuracy of my functions I predict the probabilities to make sure I get values close to 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_features(df):\n",
    "    # Create indicator features\n",
    "    df['underperformer'] = ((df['last_evaluation'] < 0.6) & (df['last_evaluation_missing'] == 0)).astype(int)\n",
    "    df['unhappy'] = (df['satisfaction'] < 0.2).astype(int)\n",
    "    df['overachiever'] = ((df['last_evaluation'] > 0.8) & (df['satisfaction'] > 0.7)).astype(int)\n",
    "    \n",
    "    # Create new dataframe with dummy features\n",
    "    df = pd.get_dummies(df, columns=['department','salary'])\n",
    "    \n",
    "    # Return augmented DataFrame\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create augmented_new_data\n",
    "augmented_data = engineer_features(cleaned_data)\n",
    "\n",
    "# Display first 5 rows\n",
    "augmented_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities\n",
    "pred = model.predict_proba(augmented_data)\n",
    "\n",
    "# Print first 5 predictions\n",
    "pred[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center; margin: 40px 0 40px 0; font-weight:bold\">\n",
    "<a href=\"#toc\">Back to Contents</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br id=\"model-class\">\n",
    "### 3. Construct a model class\n",
    "\n",
    "Great, now I'll package these functions together into a single **model class**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmployeeRetentionModel:\n",
    "    \n",
    "    def __init__(self, model_location):\n",
    "        with open(model_location, 'rb') as f:\n",
    "            self.model = pickle.load(f)\n",
    "    \n",
    "    def predict_proba(self, X_new, clean=True, augment=True):\n",
    "        if clean:\n",
    "            X_new = self.clean_data(X_new)\n",
    "        \n",
    "        if augment:\n",
    "            X_new = self.engineer_features(X_new)\n",
    "        \n",
    "        return X_new, self.model.predict_proba(X_new)\n",
    "    \n",
    "    # Add functions here\n",
    "    def clean_data(self, df):\n",
    "        df.drop_duplicates()\n",
    "        df = df[df.department != 'temp']\n",
    "        df['filed_complaint'] = df['filed_complaint'].fillna(0)\n",
    "        df['recently_promoted'] = df['recently_promoted'].fillna(0)\n",
    "        df.department.replace('information_technology', 'IT', inplace=True)\n",
    "        df['department'].fillna('Missing', inplace=True)\n",
    "        df['last_evaluation_missing'] = df['last_evaluation'].isnull().astype(int)\n",
    "        df['last_evaluation'].fillna(0, inplace=True)\n",
    "        return df\n",
    "    \n",
    "    def engineer_features(self, df):\n",
    "        df['underperformer'] = ((df['last_evaluation'] < 0.6) & (df['last_evaluation_missing'] == 0)).astype(int)\n",
    "        df['unhappy'] = (df['satisfaction'] < 0.2).astype(int)\n",
    "        df['overachiever'] = ((df['last_evaluation'] > 0.8) & (df['satisfaction'] > 0.7)).astype(int)\n",
    "        df = pd.get_dummies(df, columns=['department','salary'])\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center; margin: 40px 0 40px 0; font-weight:bold\">\n",
    "<a href=\"#toc\">Back to Contents</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span id=\"jupyter\"></span>\n",
    "### 4. Jupyter notebook\n",
    "\n",
    "There are 2 different ways to deploy models.\n",
    "1. Keep it in Jupyter Notebook\n",
    "2. Port it to an executable script\n",
    "\n",
    "Since I prefer to work in Jupyter notebooks I'm deciding to keep the model in a Jupyter Notebook, I can directly use the model class defined earlier.\n",
    "\n",
    "To demonstrate I simply initialize an instance of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an instance\n",
    "retention_model = EmployeeRetentionModel('final_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If implemented correctly, these next three statements should all work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict raw data\n",
    "_, pred1 = retention_model.predict_proba(raw_data, clean=True, augment=True)\n",
    "\n",
    "# Predict cleaned data\n",
    "_, pred2 = retention_model.predict_proba(cleaned_data, clean=False, augment=True)\n",
    "\n",
    "# Predict cleaned and augmented data\n",
    "_, pred3 = retention_model.predict_proba(augmented_data, clean=False, augment=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the way, <code style=\"color:steelblue\">_, pred1 =</code> simply means we're throwing away the first object that's returned (which was <code style=\"color:steelblue\">X_new</code>).\n",
    "\n",
    "Their predictions should all be equivalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should be true\n",
    "np.array_equal(pred1, pred2) and np.array_equal(pred2, pred3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center; margin: 40px 0 40px 0; font-weight:bold\">\n",
    "<a href=\"#toc\">Back to Contents</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center; margin: 40px 0 40px 0; font-weight:bold\">\n",
    "<a href=\"#toc\">Back to Contents</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<br>\n",
    "## Next Steps\n",
    "As a reminder, here are a few things we did in this module:\n",
    "* Created confirmed your model was saved correctly.\n",
    "* Compiled data cleaning and feature engineering functions from code you wrote in past modules.\n",
    "* Packaged everything together in a custom model class.\n",
    "* Applied your model to raw data in Jupyter Notebook.\n",
    "\n",
    "<div style=\"text-align:center; margin: 40px 0 40px 0; font-weight:bold\">\n",
    "<a href=\"#toc\">Back to Contents</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
